{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Producer - Event Replay\n",
    "\n",
    "Replay training ratings to Kafka for streaming processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import pandas as pd\n",
    "from kafka import KafkaProducer, KafkaAdminClient\n",
    "from kafka.admin import NewTopic\n",
    "from kafka.errors import NoBrokersAvailable, TopicAlreadyExistsError\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are in docker with env vairables set but as a failsafe we will have this.\n",
    "KAFKA_SERVERS = os.getenv(\n",
    "    \"KAFKA_BOOTSTRAP_SERVERS\",\n",
    "    \"kafka-broker-1:19092,kafka-broker-2:19092,kafka-broker-3:19092\"\n",
    ")\n",
    "TOPIC = \"movielens-ratings\"\n",
    "DATA_PATH = Path(\"../data/processed/train_ratings_session_ordered.csv\")\n",
    "\n",
    "# replay settings\n",
    "EVENTS_PER_SEC = 10000  # adjust based on cluster capacity\n",
    "\n",
    "print(f\"Kafka: {KAFKA_SERVERS}\")\n",
    "print(f\"Topic: {TOPIC}\")\n",
    "print(f\"Data: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_kafka(servers, retries=30):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            admin = KafkaAdminClient(bootstrap_servers=servers)\n",
    "            admin.close()\n",
    "            print(f\"Kafka ready (attempt {i+1})\")\n",
    "            return True\n",
    "        except NoBrokersAvailable:\n",
    "            print(f\"Waiting... ({i+1}/{retries})\")\n",
    "            time.sleep(2)\n",
    "    return False\n",
    "\n",
    "def create_topic(servers, topic, partitions=8):\n",
    "    rf = 2 if \",\" in servers else 1\n",
    "    try:\n",
    "        admin = KafkaAdminClient(bootstrap_servers=servers)\n",
    "        admin.create_topics([NewTopic(topic, partitions, rf)])\n",
    "        print(f\"Created topic: {topic} ({partitions} partitions, rf={rf})\")\n",
    "        admin.close()\n",
    "    except TopicAlreadyExistsError:\n",
    "        print(f\"Topic exists: {topic}\")\n",
    "\n",
    "if wait_for_kafka(KAFKA_SERVERS):\n",
    "    create_topic(KAFKA_SERVERS, TOPIC)\n",
    "else:\n",
    "    print(\"Kafka not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RatingEvent:\n",
    "    user_id: int\n",
    "    movie_id: int\n",
    "    rating: float\n",
    "    original_timestamp: int\n",
    "    event_timestamp: int\n",
    "    event_id: str\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(asdict(self)).encode('utf-8')\n",
    "\n",
    "    @classmethod\n",
    "    def from_row(cls, row, idx):\n",
    "        return cls(\n",
    "            user_id=int(row['userId']),\n",
    "            movie_id=int(row['movieId']),\n",
    "            rating=float(row['rating']),\n",
    "            original_timestamp=int(row['timestamp']),\n",
    "            event_timestamp=int(time.time() * 1000),\n",
    "            event_id=f\"evt-{idx:010d}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate-Limited Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateLimitedProducer:\n",
    "    \n",
    "    def __init__(self, servers, topic, rate):\n",
    "        self.producer = KafkaProducer(\n",
    "            bootstrap_servers=servers,\n",
    "            key_serializer=lambda k: str(k).encode('utf-8') if k else None,\n",
    "            acks='all',\n",
    "            batch_size=16384,\n",
    "            linger_ms=10\n",
    "        )\n",
    "        self.topic = topic\n",
    "        self.rate = rate\n",
    "        self.tokens = rate\n",
    "        self.last_refill = time.time()\n",
    "        self.lock = threading.Lock()\n",
    "        self.sent = 0\n",
    "        self.errors = 0\n",
    "        self.start_time = None\n",
    "\n",
    "    def _wait_for_token(self):\n",
    "        while True:\n",
    "            with self.lock:\n",
    "                now = time.time()\n",
    "                self.tokens += (now - self.last_refill) * self.rate\n",
    "                self.tokens = min(self.tokens, self.rate * 2)\n",
    "                self.last_refill = now\n",
    "                if self.tokens >= 1:\n",
    "                    self.tokens -= 1\n",
    "                    return\n",
    "            time.sleep(0.001)\n",
    "\n",
    "    def send(self, event):\n",
    "        self._wait_for_token()\n",
    "        try:\n",
    "            self.producer.send(self.topic, key=event.user_id, value=event.to_json())\n",
    "            self.sent += 1\n",
    "        except Exception:\n",
    "            self.errors += 1\n",
    "\n",
    "    def flush(self):\n",
    "        self.producer.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.flush()\n",
    "        self.producer.close()\n",
    "\n",
    "    def stats(self):\n",
    "        elapsed = time.time() - self.start_time if self.start_time else 0\n",
    "        return {\n",
    "            'sent': self.sent,\n",
    "            'elapsed': elapsed,\n",
    "            'rate': self.sent / elapsed if elapsed > 0 else 0,\n",
    "            'errors': self.errors\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay_events(data_path, servers, topic, rate, max_events=None):\n",
    "    \n",
    "    # load data\n",
    "    print(f\"Loading {data_path}...\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    if max_events:\n",
    "        df = df.head(max_events)\n",
    "    total = len(df)\n",
    "    print(f\"Loaded {total:,} ratings\")\n",
    "    \n",
    "    # estimate time\n",
    "    est_mins = total / rate / 60\n",
    "    print(f\"Target rate: {rate:,}/sec, estimated time: {est_mins:.1f} min\")\n",
    "    \n",
    "    # replay\n",
    "    producer = RateLimitedProducer(servers, topic, rate)\n",
    "    producer.start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        with tqdm(total=total, desc=\"Replaying\", unit=\"events\") as pbar:\n",
    "            for idx, row in df.iterrows():\n",
    "                event = RatingEvent.from_row(row, idx)\n",
    "                producer.send(event)\n",
    "                pbar.update(1)\n",
    "                \n",
    "                if producer.sent % 50000 == 0:\n",
    "                    s = producer.stats()\n",
    "                    pbar.set_postfix({'rate': f\"{s['rate']:.0f}/s\"})\n",
    "    finally:\n",
    "        producer.flush()\n",
    "        stats = producer.stats()\n",
    "        producer.close()\n",
    "    \n",
    "    print(\"REPLAY DONE\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Events: {stats['sent']:,}\")\n",
    "    print(f\"Time: {stats['elapsed']:.1f}s\")\n",
    "    print(f\"Rate: {stats['rate']:.1f}/sec\")\n",
    "    print(f\"Errors: {stats['errors']}\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run full replay\n",
    "stats = replay_events(\n",
    "    data_path=DATA_PATH,\n",
    "    servers=KAFKA_SERVERS,\n",
    "    topic=TOPIC,\n",
    "    rate=EVENTS_PER_SEC\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
